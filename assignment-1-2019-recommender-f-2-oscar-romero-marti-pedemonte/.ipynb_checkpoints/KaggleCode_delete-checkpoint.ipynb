{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading\n",
    "\n",
    "### **En aquestes cel·les no feu cap modificació**\n",
    "\n",
    "Carrega les dades en un DataFrame Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:522: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160112, 1) (251543, 4) (10215268, 3)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import pickle\n",
    "from os.path import join, dirname\n",
    "\n",
    "def locate(*path):\n",
    "    base = globals().get('__file__', '.')\n",
    "    return join(dirname(base), *path)\n",
    "\n",
    "def unzip(file):\n",
    "    zip_ref = zipfile.ZipFile(locate(file), 'r')\n",
    "    zip_ref.extractall(locate('data'))\n",
    "    zip_ref.close()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unzip('dades_alumnes.zip')\n",
    "\n",
    "    original_df_artists = pd.read_csv('data/artists_names.csv', index_col='musicbrainzID')\n",
    "    original_df_users = pd.read_csv('data/user_profile_train.csv', index_col='userID')\n",
    "    original_df_user_artists = pd.read_csv('data/user_artist_plays_train.csv', index_col=0)\n",
    "    \n",
    "    print(original_df_artists.shape, original_df_users.shape, original_df_user_artists.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28987, 3)\n",
      "251176 10000\n",
      "                         artistName\n",
      "musicbrainzID                      \n",
      "0                   betty blowtorch\n",
      "1                         die Ärzte\n",
      "2                 melissa etheridge\n",
      "3                         elvenking\n",
      "4              juliette & the licks\n",
      "       gender   age         country        signup\n",
      "userID                                           \n",
      "310519      m  21.0          Poland  Oct 16, 2008\n",
      "109228      m  28.0        Honduras  May 22, 2007\n",
      "35296       m  28.0          Turkey   May 5, 2007\n",
      "291224      m  22.0        Slovakia  May 11, 2008\n",
      "151053      m  26.0  United Kingdom  Dec 24, 2007\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "121",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-143-1ccacbf38a54>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginal_df_artists\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginal_df_users\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginal_df_users\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m121\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'age'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginal_df_users\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m121\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginal_df_user_artists\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2141\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2142\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2144\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_get_value\u001b[1;34m(self, index, col, takeable)\u001b[0m\n\u001b[0;32m   2537\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2538\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2539\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2540\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2541\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 121"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    df_user_artists = original_df_user_artists[original_df_user_artists.userID < 1000]\n",
    "    df_user_artists_reduced = original_df_user_artists[original_df_user_artists.userID < 500]\n",
    "    print(df_user_artists.shape)\n",
    "    print(len(original_df_user_artists['userID'].unique()), len(original_df_user_artists['musicbrainzID'].unique()))\n",
    "    print(original_df_artists.head())\n",
    "    print(original_df_users.head())\n",
    "    print(original_df_users.at[121, 'age'])\n",
    "    print(original_df_users.index(121))\n",
    "    print(original_df_user_artists.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anàlisis de les dades\n",
    "\n",
    "El primer que haurem de fer és analitzar les dades mitjançant diferents funcions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_users(df):\n",
    "    \"\"\"\n",
    "    Retorna el nombre d'usuaris en el dataframe\n",
    "    \n",
    "    :param df: DataFrame dels usuaris\n",
    "    :return : Enter, nombre d'usuaris\n",
    "    \"\"\"\n",
    "    return len(df.index)\n",
    "\n",
    "def count_artits(df):\n",
    "    \"\"\"\n",
    "    Retorna el nombre d'artistes en el dataframe\n",
    "    \n",
    "    :param df: DataFrame dels artistes\n",
    "    :return : Enter, nombre d'artistes\n",
    "    \"\"\"\n",
    "    return len(df.index)\n",
    "\n",
    "def get_users(df):\n",
    "    \"\"\"\n",
    "    Retorna els ids dels usuaris\n",
    "    \n",
    "    :params df: DataFrame original_df_users\n",
    "    :return : Llista, tupla, pd.Series o indexos de pandas amb les ids\n",
    "    \"\"\"\n",
    "    return df.index\n",
    "\n",
    "def get_artits(df):\n",
    "    \"\"\"\n",
    "    Retorna els ids dels artites\n",
    "    \n",
    "    :params df: DataFrame df_user_artists\n",
    "    :return : Llista, tupla, pd.Series o indexos de pandas amb les ids\n",
    "    \"\"\"\n",
    "    return df.index\n",
    "\n",
    "def total_reproductions(df):\n",
    "    \"\"\"\n",
    "    Retorna la quantitat de reproduccions totals guardades al dataframe\n",
    "    \n",
    "    :params df: DataFrame df_user_artists\n",
    "    :return : Enter, nombre de reproduccions\n",
    "    \"\"\"\n",
    "    return df['plays'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_users: 251543\n",
      "count_artits: 160112\n",
      "get_users: Int64Index([310519, 109228,  35296, 291224, 151053, 267414,  63446,  80577,\n",
      "            187410, 339146,\n",
      "            ...\n",
      "             43472, 130769,  66696, 315919,  98574, 226675,  81761, 103020,\n",
      "            104679,  73210],\n",
      "           dtype='int64', name='userID', length=251543)\n",
      "get_artits: Int64Index([     0,      1,      2,      3,      4,      5,      6,      7,\n",
      "                 8,      9,\n",
      "            ...\n",
      "            160103, 160104, 160105, 160106, 160107, 160108, 160109, 160110,\n",
      "            160111, 160112],\n",
      "           dtype='int64', name='musicbrainzID', length=160112)\n",
      "total_reproductions: 2356118519\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    print('count_users: {}'.format(count_users(original_df_users)))\n",
    "    print('count_artits: {}'.format(count_artits(original_df_artists)))\n",
    "    print('get_users: {}'.format(get_users(original_df_users)))\n",
    "    print('get_artits: {}'.format(get_artits(original_df_artists)))\n",
    "    print('total_reproductions: {}'.format(total_reproductions(original_df_user_artists)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementació\n",
    "\n",
    "Recordeu, seguiu els pydoc i compliu amb el que diuen!\n",
    "\n",
    "El primer que haurem de fer és construir una matriu que ens serveixi, d'alguna forma, com a indicatiu de preferències de cada persona. Per tal efecte, construirem una matriu $m\\times n$, de $m$ usuaris per $n$ artistes (items), on cada entrada $i,j$ serà el nombre de vegades que la persona $i$ a escoltat l'artista $j$.\n",
    "\n",
    "<img src=\"./img/Mat.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix, dok_matrix\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "def to_dense(array):\n",
    "    \"\"\"\n",
    "    Accepta una csr_matrix, dok_matrix o matrix i la converteix en una \n",
    "    np.array normal, densa.\n",
    "    \n",
    "    :param array: Array a convertir\n",
    "    :return: np.array densa, sense cap dimensió de tamany 1\n",
    "    \"\"\"\n",
    "    try:\n",
    "        array = array.todense()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return np.array(array).squeeze()\n",
    "    \n",
    "def build_counts_table(df):\n",
    "    \"\"\"\n",
    "    Retorna una csr_matrix on les columnes són els `items`, les files `user_id` i els valors\n",
    "    el nombre de vegades que un usuari ha escoltat un `artist`\n",
    "    \n",
    "    :param df: DataFrame original després de creuar-lo\n",
    "    :return: Una tupla constistent de:\n",
    "        * La csr_matrix descrita\n",
    "        * Els indexos corresponents a cada fila (el userID de la fila `i` corresponent a l'element `i` d'aquesta array)\n",
    "        * Les columnes corresponents a cada columna (el musicbrainzID de la columna `j` correspon a l'element `j` d'aquesta array)\n",
    "    \"\"\"\n",
    "    # Ids, sense repeticions i ordenats\n",
    "    user_ids = CategoricalDtype(sorted(df.userID.unique()), ordered=True)\n",
    "    music_ids = CategoricalDtype(sorted(df.musicbrainzID.unique()), ordered=True)\n",
    "\n",
    "    # Conversió a csr\n",
    "    row = df.userID.astype(user_ids).cat.codes\n",
    "    col = df.musicbrainzID.astype(music_ids).cat.codes\n",
    "    sparse_matrix = csr_matrix((df[\"plays\"], (row, col)), \\\n",
    "                           shape=(user_ids.categories.size, music_ids.categories.size))\n",
    "\n",
    "    return sparse_matrix, user_ids, music_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count(counts, indexes, columns, user_id, artist_id):\n",
    "    \"\"\"\n",
    "    Exemple: donat un ID d'usuari i un ID d'artista, retorna\n",
    "        el valor corresponent de la matriu `counts`\n",
    "    \n",
    "    :param counts, indexes, columns: Tupla retornada per `build_counts_table`\n",
    "    :param user_id: ID de l'usuari\n",
    "    :param artist_id: ID de l'artista\n",
    "    :return: Enter amb el nombre de vegades que s'ha escoltat\n",
    "    \"\"\"\n",
    "    row = indexes.categories.get_loc(user_id)\n",
    "    col = columns.categories.get_loc(artist_id)\n",
    "    return counts[row, col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_active_users(counts, indexes, columns, n):\n",
    "    \"\"\"\n",
    "    Exemple: Retorna els ids dels n usuaris que més reproduccions han acumulat\n",
    "    \n",
    "    :param counts, indexes, columns: Tupla retornada per `build_counts_table`\n",
    "    :param n: Quanitat d'usuaris\n",
    "    :return: Llista, tupla o pd.Series de userID dels n usuaris\n",
    "    \"\"\"\n",
    "    \n",
    "    # Operate with the sparse matrix, convert to dense the result (as it has much fewer entries)\n",
    "    sums = to_dense(counts.sum(axis=1))\n",
    "    # Get indices\n",
    "    indices = sums.argsort()\n",
    "    return indexes.categories[indices[-n:]]\n",
    "\n",
    "def top_reproduced_artits(counts, indexes, columns, n):\n",
    "    \"\"\"\n",
    "    Exemple: Retorna els ids dels n artistes més escoltats\n",
    "    \n",
    "    :param counts, indexes, columns: Tupla retornada per `build_counts_table`\n",
    "    :param n: Quanitat d'artistes\n",
    "    :return: Llista, tupla o pd.Series de artistID dels n artistes\n",
    "    \"\"\"\n",
    "    sums = to_dense(counts.sum(axis=0))\n",
    "    # Get indices\n",
    "    indices = sums.argsort()\n",
    "    return columns.categories[indices[-n:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(251176, 10000)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf823bd98bdc4c9588b132599f4dce28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(45878, 3)\n",
      "(1000, 6930)\n",
      "2796\n",
      "Int64Index([13745, 340377, 105650, 205585, 20683], dtype='int64')\n",
      "Int64Index([13745, 340377, 105650, 205585, 20683], dtype='int64')\n",
      "Int64Index([282, 217, 311, 158, 246], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "if __name__ == '__main__':\n",
    "    counts, indexes, columns = build_counts_table(original_df_user_artists)\n",
    "    print(counts.shape)\n",
    "    \n",
    "    users_id_list = np.array(top_active_users(counts, indexes, columns, 1000))\n",
    "    \n",
    "    df_user_artists = original_df_user_artists[original_df_user_artists.userID == -1 ]\n",
    "    for iden in tqdm_notebook(users_id_list):\n",
    "        df_append = original_df_user_artists[original_df_user_artists.userID == iden ]\n",
    "        df_user_artists = pd.concat((df_user_artists, df_append))\n",
    "    \n",
    "    print(df_user_artists.shape)\n",
    "    \n",
    "    counts_problem, indexes_problem, columns_problem = build_counts_table(df_user_artists)\n",
    "    print(counts_problem.shape)\n",
    "    \n",
    "    count = get_count(counts, indexes, columns, 111, 3323)\n",
    "    print(count)\n",
    "    \n",
    "    top_users = top_active_users(counts_problem, indexes_problem, columns_problem, 5)\n",
    "    print(top_users)\n",
    "    \n",
    "    top_users1 = top_active_users(counts, indexes, columns, 5)\n",
    "    print(top_users1)\n",
    "    \n",
    "    top_artists = top_reproduced_artits(counts_problem, indexes_problem, columns_problem, 5)\n",
    "    print(top_artists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[105650 205585  20683]\n"
     ]
    }
   ],
   "source": [
    "print(users_id_list[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "def similarity(x, y):\n",
    "    \"\"\"\n",
    "    Similitud entre x i y\n",
    "    \n",
    "    :param x: Primer vector, com a np.array\n",
    "    :param y: Segon vector, com a np.array\n",
    "    :return : Escalar (float) corresponent a la similitud\n",
    "    \"\"\"\n",
    "    and_oper = x*y\n",
    "    and_oper[np.isnan(and_oper)] = 0\n",
    "    x = x[and_oper != 0]\n",
    "    y = y[and_oper != 0]\n",
    "    if len(x) < 5: return 0\n",
    "    else:\n",
    "        sim = stats.pearsonr(x, y)[0]\n",
    "        if np.isnan(sim): return 0\n",
    "        elif sim > 0:\n",
    "            match = (len(x)**2)/(len(x)**2 + 5)\n",
    "            return sim*match\n",
    "        else: return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    x = np.array([1, 2, 9, np.nan, 2])\n",
    "    y = np.array([1, 1, 2, 8., 3])\n",
    "    z = np.array([0,0,0,0,0])\n",
    "    print(similarity(x, y))\n",
    "    print(similarity(z, z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriu de similituds\n",
    "\n",
    "Per fer recomanació col·laborativa existeixen dues opcions, fer un recomanador basat en usuaris o un en ítems:\n",
    "\n",
    "* Recomanador basat en usuaris:\n",
    "Considera la matriu $M\\times N: \\text{usuaris}\\times\\text{items}$, per recomanar t'hauràs de basar en les similituds entre els usuaris.\n",
    "\n",
    "* Recomanador basat en items:\n",
    "Considera la matriu $M\\times N: \\text{items}\\times\\text{usuaris}$, per recomanar t'hauràs de basar en les similituds entre els ítems.\n",
    "\n",
    "Construeix una matriu de mida $M\\times M$ on cada posició $i,j$ indica la distància entre l'element $i$ i el $j$. Així doncs, si estàs fent un recomanador basat en usuaris, `matriu[2, 3]` contindrà la similitud entre l'usuari 2 i el 3. En canvi, si l'estàs fent basat en ítems, `matriu[2, 3]` contindrà la similitud entre l'ítem 2 i el 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "\n",
    "def similarity_matrix(similarity_function, counts, indexes, df_users):\n",
    "    \"\"\"\n",
    "    Retorna una matriu dok_matrix (sparse) de mida M x M on la posició\n",
    "    (i, j) indica la similitud entre els usuaris `i` i `j` (resp. items).\n",
    "    \n",
    "    No necessàriament totes les posicions han de ser obligatòriament omplertes.\n",
    "    Una bona implementació considerarà una matriu triangular, tenint-ho en compte\n",
    "    en les següents funcions.\n",
    "    \n",
    "    :param similarity_function: Funció que calcularà la similitud \n",
    "        entre usuaris (resp. ítems)u\n",
    "    :param counts: csr_matrix que conté el nombre de vegades que \n",
    "        un usuari ha escoltat a un `artistID`\n",
    "    :return : Matriu numpy de mida M x M amb les similituds.\n",
    "    \"\"\"    \n",
    "    # Matrix cosine\n",
    "    if similarity_function is None:\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    n = counts.shape[0] # Resp. [1] per items\n",
    "    matrix = dok_matrix((n, n)) # Empty matrix, needs to be filled\n",
    "    for i in tqdm_notebook(range(n), desc='Sim matrix:', leave=True):\n",
    "        user_list_1 = to_dense(counts[i, :])\n",
    "        user_1_ID = indexes.categories[i]\n",
    "        age_1 = df_users.at[user_1_ID, 'age']\n",
    "        for j in range(i+1, n):\n",
    "            user_list_2 = to_dense(counts[j, :])\n",
    "            user_2_ID = indexes.categories[j]\n",
    "            print('user', j, user_2_ID)\n",
    "            age_2 = df_users.at[user_2_ID, 'age']\n",
    "            if np.isnan(age_1) or np.isnan(age_2):\n",
    "                match_age = 1\n",
    "            else:\n",
    "                match_age = (100/((age_1 - age_2)**2 + 100))*0.25 + 0.75\n",
    "            matrix[i, j] = similarity_function(user_list_1, user_list_2) * match_age\n",
    "    \n",
    "    \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per cridar aquesta funció, el primer paràmetre pot ser:\n",
    "\n",
    "* Si `similarity_function` no és `None`: `similarity_function` és una funció que rep dos np.array i calcula la similitud (tipus similarity(x, y)). Utilitzant ~5000 usuaris i amb una bona implementació triga ~45min.\n",
    "* Opcionalment (no és obligatori fer-ho, penseu en Kaggle) podeu programar una funció que treballi específicament amb matrius (i no vectors). Si ho feu, cal gestionar-ho quan es rep `None`. No totes les funcions anteriorment anomenades són fàcils (ni intuïtives, ni hi caben en memòria) d'aplicar en forma matricial. Triga uns 5s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc161489e2d44ad1ba68a55d8142d966",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Sim matrix:', max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        with open('similarities_delete.pkl', 'rb') as fp:\n",
    "            similarities = pickle.load(fp)\n",
    "    except:\n",
    "        similarities = similarity_matrix(\n",
    "            similarity_function=similarity,\n",
    "            counts=counts_problem,\n",
    "            indexes=indexes_problem,\n",
    "            df_users=original_df_users\n",
    "        )\n",
    "        \n",
    "        with open('similarities_delete.pkl', 'wb') as fp:\n",
    "            pickle.dump(similarities, fp, pickle.HIGHEST_PROTOCOL)\n",
    "    print(to_dense(similarities))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generació de prediccions\n",
    "\n",
    "Per fer recomanació col·laborativa, necessitem una funció que ens doni un valor de quant bona seria la recomanació. En el nostre cas i amb les nostres dades, volem una funció que ens indiqui quants cops escoltaria un usuari un artista donat.\n",
    "\n",
    "* Si esteu fent un recomanador basat en usuaris, la puntuació per a un usuari $u$ i l'artista $i$ és\n",
    "\n",
    "$$pred(u, i) = \\hat{r}_{u,i} = \\frac{\\sum_{p\\neq u,r_{p,i}>0} sim(u, p)\\cdot r_{p,i}}{\\sum_{p\\neq u,r_{p,i}>0} sim(u, p)}$$\n",
    "\n",
    "On $r_{u,i}$ indica el nombre de vegades que l'usuari $u$ ha escoltat l'l'ítem $i$.\n",
    "\n",
    "És a dir, per cada usuari $p$ diferent de $u$ si aquest usuari ha escoltat algun cop el producte $i$, la similitud entre $p$ i $u$ multiplicada pel nombre de vegades que l'usuari $p$ ha escoltat l'l'ítem $i$ ($r_{p,i}$).\n",
    "\n",
    "Pondera't per la suma de les similituds.\n",
    "\n",
    "* Anàlogament, si està basat en ítem, la puntuació per a un usuari $u$ i ítem $i$ és\n",
    "\n",
    "$$pred(u, i) = \\hat{r}_{u,i} = \\frac{\\sum_{j\\neq i,r_{u,j}>0} sim(i, j)\\cdot r_{u,j}}{\\sum_{j\\neq i,r_{u,j}>0} sim(i, j)}$$\n",
    "\n",
    "On $r_{u,i}$ indica el nombre de vegades que l'usuari $u$ ha escoltat l'ítem $j$.\n",
    "\n",
    "És a dir, per cada ítem $j$ diferent de $i$ si l'usuari al qui recomanem ha escoltat l'artista $j$, la similitud entre $i$ i $j$ multiplicada pel nombre de vegades que l'usuari al qui recomanem $u$ ha escoltat l'ítem $j$ ($r_{u,j}$)\n",
    "\n",
    "Pondera't per la suma de les similituds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixeu-vos que, sigui quin sigui el cas, al final estem fent el producte escalar entre dos vectors. Concretament, el producte escalar entre les similituds i les reproduccions. Fes una funció que calculi aquest resultat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(counts, indexes, columns, similarities, user, item):\n",
    "    \"\"\"\n",
    "    Extreu les similituds i el nombre de vegades que un usuari ha escoltat un artista\n",
    "    (resp. nombre de vegades que cada usuari ha escoltat l'artista) i:\n",
    "    \n",
    "    * Si estàs implementant basat en usuaris:\n",
    "        Donades les similituds i el nombre de vegades que l'usuari ha escoltat\n",
    "        cada artista, retorna la predicció que indica quants cops escoltara \n",
    "        l'usuari un nou artista.\n",
    "        \n",
    "    * Si estàs implementant basat en items:\n",
    "        Donades les similituds i el nombre de vegades que l'artista a recomanar ha\n",
    "        estat escoltat per cada usuari, retorna la predicció que indica quants cops\n",
    "        escoltaria l'usuari un nou artista.        \n",
    "    \n",
    "    :param counts, indexes, columns: Tupla retornada per `build_counts_table`\n",
    "    :param similarities: Matriu de similituds\n",
    "    :param user: ID de l'usuari per la predicció\n",
    "    :param item: ID de l'artista / item per la predicció    \n",
    "    :return : Retorna un escalar (float) amb la predicció\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    user_index = indexes.categories.get_loc(user)\n",
    "    item_index = columns.categories.get_loc(item)\n",
    "    row_sim_1 = to_dense(similarities[:user_index, user_index])\n",
    "    row_sim_2 = to_dense(similarities[user_index, user_index + 1:])\n",
    "    try:\n",
    "        row_sim = np.concatenate((row_sim_1, row_sim_2), axis = None)\n",
    "    except:\n",
    "        print(row_sim_1.shape, row_sim_2.shape)\n",
    "    item_list = to_dense(counts[:, item_index])\n",
    "    item_list = np.delete(item_list, user_index)\n",
    "    row_sim_zeros = np.copy(row_sim)\n",
    "    row_sim_zeros[item_list == 0] = 0\n",
    "    numerador = np.dot(row_sim, item_list)\n",
    "    denominador = np.sum(row_sim_zeros)\n",
    "    if numerador == 0: return 0.\n",
    "    else: return numerador/denominador\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1367.0\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    print(score(counts_problem, indexes_problem, columns_problem, similarities, 20683, 886))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feu una funció que donat un usuari calculi per cada item que no ha escoltat la puntuació d'aquest. La funció retorna els $N$ items més ben puntuats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_n_items(counts, indexes, columns, similarities, user, N):\n",
    "    \"\"\"\n",
    "    Donat un usuari calcula per cada ítem/artista que no ha escoltat la puntuació d'aquest. \n",
    "    La funció retorna els $N$ ítems més ben puntuats.\n",
    "    \n",
    "    :param counts, indexes, columns: Tupla retornada per `build_counts_table`\n",
    "    :param similarities: Matriu de similituds\n",
    "    :param user: Identificador de l'usuari\n",
    "    :param N: Nombre d'ítems que volem que siguin recomanats.\n",
    "    :return : Llista amb els IDs dels ítems recomanats\n",
    "    \"\"\"\n",
    "    \n",
    "    user_index = indexes.categories.get_loc(user)\n",
    "    user_list = to_dense(counts[user_index, :])\n",
    "    scores = np.ones_like(user_list)*(-1.)\n",
    "    for item_index in tqdm_notebook(range(len(user_list)), desc='Recomending:', leave=False):\n",
    "        if user_list[item_index] == 0: # calcula score\n",
    "            item_ID = columns.categories[item_index]\n",
    "            scores[item_index] = score(counts, indexes, columns, similarities, user, item_ID)\n",
    "    items_sorted = np.argsort(-scores)\n",
    "    num_to_show = np.min((len(items_sorted), N))\n",
    "    showable = np.array([], dtype=np.int)\n",
    "    for i in range(num_to_show):\n",
    "        showable = np.append(showable, columns.categories[items_sorted[i]])\n",
    "            \n",
    "    return showable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Recomending:', max=6930), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4313    41   985   283   770   618  4319 17481  2575   475]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    out = recommend_n_items(counts_problem, indexes_problem, columns_problem, similarities, 20683, 10)\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Possibles millores \n",
    "\n",
    "Per implementar millores, dupliqueu el notebook i feu-ho en la còpia!\n",
    "\n",
    "Deixeu aquest notebook amb la implementació base.\n",
    "\n",
    "**1) És Jaccard la millor mesura de similitud per les nostres dades?**\n",
    "Jaccard no té en compte la cardinalitat, únicament els elements no nuls. És, per les dades de reproduccions, una aproximació adequada?\n",
    "Si ho és, creus que el càlcul de recomanació col·laborativa és el més adhient? Mira el punt 3\n",
    "\n",
    "**2) Utilització completa de les dades:**\n",
    "Fer servir `df_original` tindrà (possiblement) resultats més fiables, però trigarà molt més que amb la versió reduida `df`. Pots canviar tant el nombre de dades utilitzades com quines dades es seleccionen.\n",
    "\n",
    "**3) Normalització: Prediccions escalades al domini de l'usuari:**\n",
    "Els usuaris escolten en diferent mesura als artites, uns més vegades, d'altres menys. Fent servir la següent formula, escalem la predicció a la mitja de l'usuari:\n",
    "$$pred(u, i) = \\hat{r}_{u,i} = \\bar{r_u} + \\frac{\\sum_{p\\neq u,r_{p,i}>0} sim(u, p)\\cdot (r_{p,i}-\\bar{r_i})}{\\sum_{p\\neq u,r_{p,i}>0} sim(u, p)}$$\n",
    "on $\\bar{r_u}$ és la mitjana de compres de l'usuari *u* i $\\bar{r_i}$ la mitja de reproduccions de l'artista *i*.\n",
    "    \n",
    "**4) Valor del nombre d'elements codificats: **\n",
    "Redueix la similitud entre els usuaris si el nombre de reproduccions és baix o descarta (en entrenament) aquells usuaris amb un petit nombre d'artistes escoltats.\n",
    "\n",
    "**5) Augment de la similitud: **\n",
    "Incrementeu el pes als usuaris que són realment similars (~ = 1)\n",
    "\n",
    "**6) Selecció d'usuaris semblants: **\n",
    "Només s'utilitza un subconjunt d'usuaris similars, descartant tots aquells usuaris poc similars.\n",
    "\n",
    "\n",
    "Totes aquestes tècniques es poden aplicar d'igual manera en la recomanació col·laborativa per usuaris o ítems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle\n",
    "\n",
    "Teniu la competició a la següent URL:\n",
    "\n",
    "https://www.kaggle.com/t/4a3fd7b1e44c40a5a208c6da21a23d05\n",
    "\n",
    "Si heu seguit tots els pydoc, el següent codi funcionarà directament sense canvis (@30min)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52ac9c60d5f1479d956b5da281700d32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Sim matrix:', max=1099), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "121",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-138-d3da3173acff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'merged_similarities_kaggle_del.pkl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m             \u001b[0mmerged_similarities\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'merged_similarities_kaggle_del.pkl'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-138-d3da3173acff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[0mcounts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmerged_counts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[0mindexes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmerged_indexes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m             \u001b[0mdf_users\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moriginal_df_users\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m         )\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-131-8b894682f070>\u001b[0m in \u001b[0;36msimilarity_matrix\u001b[1;34m(similarity_function, counts, indexes, df_users)\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[0muser_2_ID\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategories\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[1;31m# print('user', j, user_2_ID)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m             \u001b[0mage_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_users\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0muser_2_ID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'age'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mage_1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mage_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m                 \u001b[0mmatch_age\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2141\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2142\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2144\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_get_value\u001b[1;34m(self, index, col, takeable)\u001b[0m\n\u001b[0;32m   2537\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2538\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2539\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2540\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2541\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 121"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    counts, indexes, columns = build_counts_table(original_df_user_artists)\n",
    "    print(counts.shape)\n",
    "    \n",
    "    users_id_list = np.array(top_active_users(counts, indexes, columns, 8000))\n",
    "    \n",
    "    df_user_artists = original_df_user_artists[original_df_user_artists.userID == -1 ]\n",
    "    for iden in tqdm_notebook(users_id_list):\n",
    "        df_append = original_df_user_artists[original_df_user_artists.userID == iden ]\n",
    "        df_user_artists = pd.concat((df_user_artists, df_append))\n",
    "    \n",
    "    print(df_user_artists.shape)\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        from tqdm import tqdm_notebook\n",
    "    except:\n",
    "        def tqdm_notebook(a, *_, **__): return a\n",
    "    \n",
    "    # Fetch kaggle public data and merge\n",
    "    kaggle_df_user_artists = pd.read_csv('data/user_artist_plays_public_kaggle.csv')\n",
    "    merged_df_user_artists = pd.concat((df_user_artists, kaggle_df_user_artists))\n",
    "    \n",
    "    # Obtain counts\n",
    "    merged_counts, merged_indexes, merged_columns = build_counts_table(merged_df_user_artists)\n",
    "    \n",
    "    # Similarity\n",
    "    try:\n",
    "        with open('merged_similarities_kaggle_del.pkl', 'rb') as fp:\n",
    "            merged_similarities = pickle.load(fp)\n",
    "    except:\n",
    "        merged_similarities = similarity_matrix(\n",
    "            similarity_function=similarity,\n",
    "            counts=merged_counts,\n",
    "            indexes=merged_indexes,\n",
    "            df_users=original_df_users\n",
    "        )\n",
    "        \n",
    "        with open('merged_similarities_kaggle_del.pkl', 'wb') as fp:\n",
    "            pickle.dump(merged_similarities, fp, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    results = pd.DataFrame(columns=['user_id', 'music_id'])\n",
    "    \n",
    "    for idx, user in enumerate(tqdm_notebook(kaggle_df_user_artists.userID.unique())):\n",
    "        music_ids = recommend_n_items(merged_counts, merged_indexes, merged_columns, merged_similarities, user, 10)\n",
    "        results.loc[idx] = (user, ' '.join(str(x) for x in music_ids))\n",
    "        \n",
    "    results.to_csv('submission_kaggle_del.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
